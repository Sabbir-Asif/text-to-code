{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install dependencies\n!pip install datasets transformers nltk sentencepiece","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-14T07:07:52.260558Z","iopub.execute_input":"2026-02-14T07:07:52.260988Z","iopub.status.idle":"2026-02-14T07:07:55.713804Z","shell.execute_reply.started":"2026-02-14T07:07:52.260941Z","shell.execute_reply":"2026-02-14T07:07:55.713069Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.2)\nRequirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\nRequirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.2)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.3)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\nRequirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (26.0rc2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2026.1.4)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.6.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nimport random\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T07:07:55.715806Z","iopub.execute_input":"2026-02-14T07:07:55.716170Z","iopub.status.idle":"2026-02-14T07:07:55.721349Z","shell.execute_reply.started":"2026-02-14T07:07:55.716133Z","shell.execute_reply":"2026-02-14T07:07:55.720567Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\nspecial_tokens = {\"pad_token\":\"<PAD>\", \"bos_token\":\"<SOS>\", \"eos_token\":\"<EOS>\"}\ntokenizer.add_special_tokens(special_tokens)\n\nPAD_IDX = tokenizer.pad_token_id\nSOS_IDX = tokenizer.bos_token_id\nEOS_IDX = tokenizer.eos_token_id\n\nINPUT_DIM = len(tokenizer)\nOUTPUT_DIM = len(tokenizer)\nprint(f\"Vocab size: {INPUT_DIM}, PAD={PAD_IDX}, SOS={SOS_IDX}, EOS={EOS_IDX}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T07:07:55.722292Z","iopub.execute_input":"2026-02-14T07:07:55.722655Z","iopub.status.idle":"2026-02-14T07:07:57.232602Z","shell.execute_reply.started":"2026-02-14T07:07:55.722629Z","shell.execute_reply":"2026-02-14T07:07:57.231931Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a734d9f1da7c4b79a0e7acc51195d0fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81980aaf00cc4d839800adb02aa462a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4362064ffd6a47299576d96cb5becfc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1871652dbc3d4e978e8d0fa0703c2f59"}},"metadata":{}},{"name":"stdout","text":"Vocab size: 30525, PAD=30522, SOS=30523, EOS=30524\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"dataset = load_dataset(\"Nan-Do/code-search-net-python\")\nfull_data = dataset[\"train\"].select(range(7000))  # small subset for speed\n\n# Split 80% train, 10% val, 10% test\nsplit1 = full_data.train_test_split(test_size=0.2, seed=42)\ntrain_data = split1[\"train\"]\ntemp_data = split1[\"test\"]\nsplit2 = temp_data.train_test_split(test_size=0.5, seed=42)\nval_data = split2[\"train\"]\ntest_data = split2[\"test\"]\n\nprint(len(train_data), len(val_data), len(test_data))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T07:07:57.233551Z","iopub.execute_input":"2026-02-14T07:07:57.233905Z","iopub.status.idle":"2026-02-14T07:08:07.725837Z","shell.execute_reply.started":"2026-02-14T07:07:57.233880Z","shell.execute_reply":"2026-02-14T07:08:07.725230Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bdcf752e00e490ca75a369f7eb7ae6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00004-ee77a7de79eb2a(â€¦):   0%|          | 0.00/155M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3c326d5b36e4c2eb61157ecf576338b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00001-of-00004-648b3bede2edf6(â€¦):   0%|          | 0.00/139M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd832502ef9f4124b24b2604040db72a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00002-of-00004-1dfd72b171e6b2(â€¦):   0%|          | 0.00/153M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"122d1dfa7e9a4749bd3d388d3ebc30a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00003-of-00004-184ab6d0e3c690(â€¦):   0%|          | 0.00/151M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06c0d5a82673456287a5879ac28b78ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/455243 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98f2a223d2914d99878a27837ccdaa3b"}},"metadata":{}},{"name":"stdout","text":"5600 700 700\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# --------------------------\n# 3. DATASET CLASS\n# --------------------------\nclass CodeDataset(Dataset):\n    def __init__(self, data, tokenizer, max_doc_len=50, max_code_len=80):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.max_doc_len = max_doc_len\n        self.max_code_len = max_code_len\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data[idx]\n        # tokenize docstring and code\n        doc = self.tokenizer.encode(item[\"docstring\"], truncation=True,\n                                    max_length=self.max_doc_len, add_special_tokens=False)\n        code = self.tokenizer.encode(item[\"code\"], truncation=True,\n                                     max_length=self.max_code_len, add_special_tokens=False)\n        return {\"doc\": doc, \"code\": code}\n\ndef collate_fn(batch):\n    docs = [b[\"doc\"] for b in batch]\n    codes = [b[\"code\"] for b in batch]\n    max_doc = max(len(d) for d in docs)\n    max_code = max(len(c) for c in codes)\n\n    doc_pad, trg_in, trg_out = [], [], []\n    for d,c in zip(docs,codes):\n        doc_pad.append(d + [PAD_IDX]*(max_doc-len(d)))\n        trg_in.append([SOS_IDX] + c + [PAD_IDX]*(max_code-len(c)))\n        trg_out.append(c + [EOS_IDX] + [PAD_IDX]*(max_code-len(c)))\n\n    return {\n        \"src\": torch.tensor(doc_pad),\n        \"trg_in\": torch.tensor(trg_in),\n        \"trg_out\": torch.tensor(trg_out)\n    }\n\n# Dataloaders\ntrain_loader = DataLoader(CodeDataset(train_data, tokenizer), batch_size=32, shuffle=True, collate_fn=collate_fn)\nval_loader   = DataLoader(CodeDataset(val_data, tokenizer), batch_size=32, collate_fn=collate_fn)\ntest_loader  = DataLoader(CodeDataset(test_data, tokenizer), batch_size=32, collate_fn=collate_fn)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T07:08:07.727587Z","iopub.execute_input":"2026-02-14T07:08:07.727850Z","iopub.status.idle":"2026-02-14T07:08:07.737320Z","shell.execute_reply.started":"2026-02-14T07:08:07.727824Z","shell.execute_reply":"2026-02-14T07:08:07.736530Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# --------------------------\n# 4. MODEL\n# --------------------------\nclass Encoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, hid_dim):\n        super().__init__()\n        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=PAD_IDX)\n        self.rnn = nn.RNN(emb_dim, hid_dim)\n\n    def forward(self, src):\n        embedded = self.embedding(src)         # [seq_len, batch, emb_dim]\n        _, hidden = self.rnn(embedded)         # hidden: [1, batch, hid_dim]\n        return hidden\n\nclass Decoder(nn.Module):\n    def __init__(self, output_dim, emb_dim, hid_dim):\n        super().__init__()\n        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=PAD_IDX)\n        self.rnn = nn.RNN(emb_dim, hid_dim)\n        self.fc = nn.Linear(hid_dim, output_dim)\n\n    def forward(self, x, hidden):\n        x = x.unsqueeze(0)                     # [1, batch]\n        emb = self.embedding(x)                # [1, batch, emb_dim]\n        out, hidden = self.rnn(emb, hidden)    # out: [1, batch, hid_dim]\n        pred = self.fc(out.squeeze(0))         # [batch, vocab_size]\n        return pred, hidden\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, enc, dec, device):\n        super().__init__()\n        self.enc = enc\n        self.dec = dec\n        self.device = device\n\n    def forward(self, src, trg, teacher_forcing=0.5):\n        batch_size = trg.shape[1]\n        trg_len = trg.shape[0]\n        vocab_size = self.dec.fc.out_features\n\n        outputs = torch.zeros(trg_len, batch_size, vocab_size).to(self.device)\n        hidden = self.enc(src)\n        x = trg[0]  # first input = SOS\n\n        for t in range(1, trg_len):\n            out, hidden = self.dec(x, hidden)\n            outputs[t] = out\n            top1 = out.argmax(1)\n            x = trg[t] if random.random() < teacher_forcing else top1\n        return outputs\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = Seq2Seq(Encoder(INPUT_DIM, 128, 256), Decoder(OUTPUT_DIM, 128, 256), device).to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T07:08:07.738339Z","iopub.execute_input":"2026-02-14T07:08:07.738652Z","iopub.status.idle":"2026-02-14T07:08:08.152784Z","shell.execute_reply.started":"2026-02-14T07:08:07.738613Z","shell.execute_reply":"2026-02-14T07:08:08.152185Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# --------------------------\n# 5. TRAINING\n# --------------------------\ndef train(model, loader):\n    model.train()\n    total_loss = 0\n    for b in loader:\n        src = b[\"src\"].transpose(0,1).to(device)\n        trg_in = b[\"trg_in\"].transpose(0,1).to(device)\n        trg_out = b[\"trg_out\"].transpose(0,1).to(device)\n\n        optimizer.zero_grad()\n        output = model(src, trg_in)\n\n        output = output[1:].reshape(-1, output.shape[-1])\n        trg_out = trg_out[1:].reshape(-1)\n\n        loss = criterion(output, trg_out)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(loader)\n\ndef evaluate(model, loader):\n    model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for b in loader:\n            src = b[\"src\"].transpose(0,1).to(device)\n            trg_in = b[\"trg_in\"].transpose(0,1).to(device)\n            trg_out = b[\"trg_out\"].transpose(0,1).to(device)\n\n            output = model(src, trg_in, teacher_forcing=0)\n            output = output[1:].reshape(-1, output.shape[-1])\n            trg_out = trg_out[1:].reshape(-1)\n\n            loss = criterion(output, trg_out)\n            total_loss += loss.item()\n    return total_loss / len(loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T07:08:08.153724Z","iopub.execute_input":"2026-02-14T07:08:08.153977Z","iopub.status.idle":"2026-02-14T07:08:08.162185Z","shell.execute_reply.started":"2026-02-14T07:08:08.153944Z","shell.execute_reply":"2026-02-14T07:08:08.161630Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# --------------------------\n# 6. GENERATION\n# --------------------------\ndef generate_code(model, docstring, max_len=80):\n    model.eval()\n    tokens = tokenizer.encode(docstring, add_special_tokens=False)\n    src = torch.tensor(tokens).unsqueeze(1).to(device)\n\n    output_tokens = []\n    with torch.no_grad():\n        hidden = model.enc(src)\n        x = torch.tensor([SOS_IDX]).to(device)\n        for _ in range(max_len):\n            out, hidden = model.dec(x, hidden)\n            top1 = out.argmax(1).item()\n            if top1 == EOS_IDX:\n                break\n            output_tokens.append(top1)\n            x = torch.tensor([top1]).to(device)\n\n    return tokenizer.decode(output_tokens)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T07:08:08.163232Z","iopub.execute_input":"2026-02-14T07:08:08.163542Z","iopub.status.idle":"2026-02-14T07:08:08.177591Z","shell.execute_reply.started":"2026-02-14T07:08:08.163510Z","shell.execute_reply":"2026-02-14T07:08:08.176712Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# --------------------------\n# 7. BLEU SCORE\n# --------------------------\nsmooth = SmoothingFunction().method1\n\ndef bleu_score(model, dataset, n_samples=100):\n    scores = []\n    for i in range(n_samples):\n        ref_text = dataset[i][\"code\"]\n        doc_text = dataset[i][\"docstring\"]\n        pred_text = generate_code(model, doc_text)\n\n        # Tokenize both reference and prediction with tokenizer\n        ref_tokens = tokenizer.encode(ref_text, add_special_tokens=False)\n        pred_tokens = tokenizer.encode(pred_text, add_special_tokens=False)\n\n        ref_tokens = [str(tok) for tok in ref_tokens]\n        pred_tokens = [str(tok) for tok in pred_tokens]\n\n        scores.append(sentence_bleu([ref_tokens], pred_tokens, smoothing_function=smooth))\n    return np.mean(scores)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T07:08:08.178586Z","iopub.execute_input":"2026-02-14T07:08:08.178937Z","iopub.status.idle":"2026-02-14T07:08:08.189846Z","shell.execute_reply.started":"2026-02-14T07:08:08.178904Z","shell.execute_reply":"2026-02-14T07:08:08.189130Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# --------------------------\n# 8. TRAIN LOOP\n# --------------------------\nbest_val_loss = float('inf')\nfor epoch in range(10):\n    train_loss = train(model, train_loader)\n    val_loss = evaluate(model, val_loader)\n    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}\")\n\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), \"best_model.pt\")\n        print(\"ðŸ’¾ Saved Best Model!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T07:08:08.190646Z","iopub.execute_input":"2026-02-14T07:08:08.190948Z","iopub.status.idle":"2026-02-14T07:22:29.007714Z","shell.execute_reply.started":"2026-02-14T07:08:08.190915Z","shell.execute_reply":"2026-02-14T07:22:29.006875Z"}},"outputs":[{"name":"stdout","text":"Epoch 1: Train Loss=6.3415, Val Loss=5.9218\nðŸ’¾ Saved Best Model!\nEpoch 2: Train Loss=5.5308, Val Loss=5.8069\nðŸ’¾ Saved Best Model!\nEpoch 3: Train Loss=5.3919, Val Loss=5.8327\nEpoch 4: Train Loss=5.2686, Val Loss=6.3155\nEpoch 5: Train Loss=5.1840, Val Loss=5.9557\nEpoch 6: Train Loss=5.1175, Val Loss=5.8516\nEpoch 7: Train Loss=5.0636, Val Loss=5.9465\nEpoch 8: Train Loss=5.0214, Val Loss=6.0190\nEpoch 9: Train Loss=4.9552, Val Loss=6.4316\nEpoch 10: Train Loss=4.9233, Val Loss=6.4434\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# --------------------------\n# 9. EVALUATION\n# --------------------------\nmodel.load_state_dict(torch.load(\"best_model.pt\"))\nmodel.to(device)\nprint(\"BLEU score on 100 test examples:\", bleu_score(model, test_data, n_samples=100))\n\n# Quick test example\nprint(\"Example docstring:\", test_data[0][\"docstring\"])\nprint(\"Generated code:\", generate_code(model, test_data[0][\"docstring\"]))\nprint(\"Reference code:\", test_data[0][\"code\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T07:24:08.214483Z","iopub.execute_input":"2026-02-14T07:24:08.214829Z","iopub.status.idle":"2026-02-14T07:24:11.835428Z","shell.execute_reply.started":"2026-02-14T07:24:08.214801Z","shell.execute_reply":"2026-02-14T07:24:11.834660Z"}},"outputs":[{"name":"stdout","text":"BLEU score on 100 test examples: 0.020252689831894953\nExample docstring: Process the inner datasets.\nGenerated code: _ _ _ (, _, _, _, _ : \" \" \" \" \" a.. \" \" \" \".. \" \" \" \".. \" \" \" \".. \" \" \" \".. \" \" \" \".. \" \" \" \".. \" \" \" \".. \" \" \" \".. \" \" \" \".. \" \" \" \".\nReference code: def process(self):\n        \"Process the inner datasets.\"\n        xp,yp = self.get_processors()\n        for ds,n in zip(self.lists, ['train','valid','test']): ds.process(xp, yp, name=n)\n        #progress_bar clear the outputs so in some case warnings issued during processing disappear.\n        for ds in self.lists:\n            if getattr(ds, 'warn', False): warn(ds.warn)\n        return self\n","output_type":"stream"}],"execution_count":14}]}